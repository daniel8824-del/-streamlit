import streamlit as st  # ìŠ¤íŠ¸ë¦¼ë¦¿ ë¼ì´ë¸ŒëŸ¬ë¦¬   
import os  # íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬
import pickle  # íŒŒì¼ ì €ì¥ ë° ë¡œë“œ
from langchain.chains import ConversationalRetrievalChain  # ëŒ€í™”í˜• ê²€ìƒ‰ ì²´ì¸
from langchain.chat_models import ChatOpenAI  # ì±—ë´‡ ëª¨ë¸
from langchain.memory import ConversationBufferMemory  # ëŒ€í™” ê¸°ë¡ ë©”ëª¨ë¦¬
from langchain.vectorstores import SKLearnVectorStore  # ë²¡í„° ì €ì¥ì†Œ
from langchain.document_loaders import PyPDFLoader  # PDF íŒŒì¼ ë¡œë“œ
from langchain.text_splitter import RecursiveCharacterTextSplitter  # í…ìŠ¤íŠ¸ ë¶„í• 
from langchain.embeddings.openai import OpenAIEmbeddings  # OpenAI ì„ë² ë”© ëª¨ë¸
from dotenv import load_dotenv  # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Streamlit Secretsì—ì„œ OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
openai_api_key = os.environ.get("OPENAI_API_KEY")
if not openai_api_key and hasattr(st, "secrets") and "OPENAI_API_KEY" in st.secrets:
    openai_api_key = st.secrets["OPENAI_API_KEY"]

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="í˜„ëŒ€ìë™ì°¨ ì•„ë°˜ë–¼ 2025 ì„¤ëª…ì„œ ì±—ë´‡",
    page_icon="ğŸš—",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ìŠ¤íƒ€ì¼ ì¶”ê°€ - ê°„ì†Œí™”ëœ ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        display: flex;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    .chat-message.user {
        background-color: #e6f7ff;
        border-left: 5px solid #1890ff;
    }
    .chat-message.bot {
        background-color: #f6ffed;
        border-left: 5px solid #52c41a;
    }
    .chat-message .avatar {
        width: 40px;
        height: 40px;
        border-radius: 50%;
        object-fit: cover;
        margin-right: 1rem;
    }
    .chat-message .message {
        flex-grow: 1;
    }
    button {
        border-radius: 4px;
        padding: 0.5rem 1rem;
        font-weight: 500;
    }
</style>
""", unsafe_allow_html=True)

# ë²¡í„° ì €ì¥ì†Œ ìƒì„± í•¨ìˆ˜
def create_vectorstore():
    """
    PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³ , ì²­í¬ë¡œ ë¶„í• í•œ í›„ ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Returns:
        SKLearnVectorStore: ìƒì„±ëœ ë²¡í„° ì €ì¥ì†Œ
    """
    try:
        # PDF íŒŒì¼ ê²½ë¡œ ì„¤ì • (data í´ë” ë‚´ì˜ ëª¨ë“  PDF íŒŒì¼)
        pdf_folder_path = "./data/"
        
        # data í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(pdf_folder_path):
            os.makedirs(pdf_folder_path, exist_ok=True)
            st.warning(f"'{pdf_folder_path}' í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            return None
        
        # PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        pdf_files = [f for f in os.listdir(pdf_folder_path) if f.endswith('.pdf')]
        
        if not pdf_files:
            st.warning(f"'{pdf_folder_path}' í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
            st.info(f"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
            st.info(f"data í´ë” ê²½ë¡œ: {os.path.abspath(pdf_folder_path)}")
            st.info(f"data í´ë” ë‚´ íŒŒì¼ ëª©ë¡: {os.listdir(pdf_folder_path) if os.path.exists(pdf_folder_path) else 'í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ'}")
            return None
        
        # ëª¨ë“  ë¬¸ì„œë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        all_docs = []
        
        # ê° PDF íŒŒì¼ ì²˜ë¦¬
        for pdf_file in pdf_files:
            pdf_path = os.path.join(pdf_folder_path, pdf_file)
            st.info(f"'{pdf_file}' íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
            
            # PDF ë¡œë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ë¡œë“œ
            loader = PyPDFLoader(pdf_path)
            documents = loader.load()
            
            # ë¬¸ì„œë¥¼ all_docsì— ì¶”ê°€
            all_docs.extend(documents)
        
        # ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,  # ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜
            chunk_overlap=200,  # ì²­í¬ ê°„ ì¤‘ë³µë˜ëŠ” ë¬¸ì ìˆ˜
            length_function=len,
        )
        
        chunks = text_splitter.split_documents(all_docs)
        st.info(f"ì´ {len(chunks)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # OpenAI API í‚¤ í™•ì¸
        if not openai_api_key:
            st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Secrets ì„¤ì •ì—ì„œ OPENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            return None
        
        # OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        
        # scikit-learn ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        vectorstore = SKLearnVectorStore.from_documents(chunks, embeddings)
        
        # sklearn_index í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists("sklearn_index"):
            os.makedirs("sklearn_index", exist_ok=True)
        
        # ë²¡í„° ì €ì¥ì†Œ ì €ì¥ (pickle ì‚¬ìš©)
        vectorstore_path = "sklearn_index/vectorstore.pkl"
        with open(vectorstore_path, "wb") as f:
            pickle.dump(vectorstore, f)
        
        if os.path.exists(vectorstore_path):
            st.success(f"ë²¡í„° ì €ì¥ì†Œê°€ '{vectorstore_path}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.error(f"ë²¡í„° ì €ì¥ì†Œ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œ: {vectorstore_path}")
        
        return vectorstore
    
    except Exception as e:
        st.error(f"ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        # ë””ë²„ê¹…ì„ ìœ„í•œ ì •ë³´ ì¶œë ¥
        st.info(f"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
        return None

# ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ í•¨ìˆ˜
@st.cache_resource
def load_vectorstore():
    """
    ì €ì¥ëœ ë²¡í„° ì €ì¥ì†Œë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    
    Returns:
        SKLearnVectorStore: ë¡œë“œëœ ë²¡í„° ì €ì¥ì†Œ
    """
    try:
        vectorstore_path = "sklearn_index/vectorstore.pkl"
        
        # ë²¡í„° ì €ì¥ì†Œ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(vectorstore_path):
            st.warning(f"ë²¡í„° ì €ì¥ì†Œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {vectorstore_path}")
            st.info("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  'ë²¡í„° ì €ì¥ì†Œ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
            # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
            st.info(f"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
            st.info(f"sklearn_index í´ë” ì¡´ì¬ ì—¬ë¶€: {os.path.exists('sklearn_index')}")
            if os.path.exists('sklearn_index'):
                st.info(f"sklearn_index í´ë” ë‚´ íŒŒì¼ ëª©ë¡: {os.listdir('sklearn_index')}")
            return None
        
        # ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
        with open(vectorstore_path, "rb") as f:
            vectorstore = pickle.load(f)
        
        st.success("ë²¡í„° ì €ì¥ì†Œë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return vectorstore
    
    except Exception as e:
        st.error(f"ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        # ë””ë²„ê¹…ì„ ìœ„í•œ ì •ë³´ ì¶œë ¥
        st.info(f"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
        return None

# ì±—ë´‡ ìƒì„± í•¨ìˆ˜
@st.cache_resource
def create_chatbot():
    """
    ì±—ë´‡ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Returns:
        ConversationalRetrievalChain: ìƒì„±ëœ ì±—ë´‡
    """
    # ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
    vectorstore = load_vectorstore()
    
    if vectorstore is None:
        return None
    
    # ëŒ€í™” ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
    
    # OpenAI API í‚¤ í™•ì¸
    if not openai_api_key:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Secrets ì„¤ì •ì—ì„œ OPENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return None
    
    # ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model_name="gpt-4o",  # gpt-3.5-turboì—ì„œ gpt-4oë¡œ ë³€ê²½
        temperature=0.2,  # ì‘ë‹µì˜ ì°½ì˜ì„± ì •ë„ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê²°ì •ì ì¸ ì‘ë‹µ)
        openai_api_key=openai_api_key
    )
    
    # ëŒ€í™”í˜• ê²€ìƒ‰ ì²´ì¸ ìƒì„±
    chatbot = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        memory=memory,
        return_source_documents=True
    )
    
    return chatbot

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'ready' not in st.session_state:
    st.session_state.ready = False

# ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.header("ì±—ë´‡ ì„¤ì •")
    
    # ì•ˆë‚´ ë©”ì‹œì§€ ì¶”ê°€
    st.info("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë²¡í„° ì €ì¥ì†Œê°€ ìƒì„±ë˜ê³  ì±—ë´‡ì´ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.")
    
    # ìˆ˜ë™ ì´ˆê¸°í™” ë²„íŠ¼ (í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©)
    with st.expander("ê³ ê¸‰ ì„¤ì •", expanded=False):
        st.caption("ì•„ë˜ ë²„íŠ¼ì€ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ì±—ë´‡ ì´ˆê¸°í™”", use_container_width=True):
                with st.spinner("ì±—ë´‡ì„ ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤..."):
                    vectorstore = load_vectorstore()
                    if vectorstore:
                        st.session_state.chatbot = create_chatbot()
                        st.session_state.ready = True
                        st.success("ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.experimental_rerun()
        
        with col2:
            if st.button("ë²¡í„° ì €ì¥ì†Œ ìƒì„±", use_container_width=True):
                with st.spinner("ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    vectorstore = create_vectorstore()
                    if vectorstore:
                        st.success("ë²¡í„° ì €ì¥ì†Œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.session_state.ready = False
                        st.info("ì´ì œ 'ì±—ë´‡ ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì±—ë´‡ì„ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.")
    
    # PDF íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥
    st.subheader("PDF íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")
    
    if uploaded_file is not None:
        try:
            # data í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
            if not os.path.exists("./data/"):
                os.makedirs("./data/", exist_ok=True)
            
            # ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
            file_path = os.path.join("./data/", uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            if os.path.exists(file_path):
                st.success(f"'{uploaded_file.name}' íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                # íŒŒì¼ ì—…ë¡œë“œ í›„ ìë™ìœ¼ë¡œ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
                with st.spinner("ë²¡í„° ì €ì¥ì†Œë¥¼ ìë™ìœ¼ë¡œ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    vectorstore = create_vectorstore()
                    if vectorstore:
                        st.success("ë²¡í„° ì €ì¥ì†Œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        # ë²¡í„° ì €ì¥ì†Œ ìƒì„± í›„ ìë™ìœ¼ë¡œ ì±—ë´‡ ì´ˆê¸°í™”
                        with st.spinner("ì±—ë´‡ì„ ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤..."):
                            st.session_state.chatbot = create_chatbot()
                            st.session_state.ready = True
                            st.success("ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
                            st.experimental_rerun()
            else:
                st.error(f"íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œ: {file_path}")
        except Exception as e:
            st.error(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            # ë””ë²„ê¹…ì„ ìœ„í•œ ì •ë³´ ì¶œë ¥
            st.info(f"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
            st.info(f"íŒŒì¼ ì´ë¦„: {uploaded_file.name}")
            st.info(f"íŒŒì¼ í¬ê¸°: {len(uploaded_file.getbuffer())} ë°”ì´íŠ¸")
    
    st.markdown("---")
    st.markdown("### ì˜ˆì‹œ ì§ˆë¬¸")
    example_questions = [
        "ì•„ë°˜ë–¼ ì—”ì§„ ì˜¤ì¼ì€ ì–´ë–»ê²Œ êµì²´í•˜ë‚˜ìš”?",
        "íƒ€ì´ì–´ ê³µê¸°ì••ì€ ì–¼ë§ˆë¡œ ìœ ì§€í•´ì•¼ í•˜ë‚˜ìš”?",
        "íƒ€ì´ì–´ê°€ í‘í¬ë‚¬ì–´. í•´ê²°ì±…ì„ ì•Œë ¤ì¤˜",
        "ì°½ë¬¸ì— ì„œë¦¬ê°€ ìê¾¸ ê»´ìš”. ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
        "ì—°ë¹„ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì´ ìˆì„ê¹Œìš”?"
    ]
    
    for q in example_questions:
        if st.button(q, use_container_width=True):
            if st.session_state.ready:
                st.session_state.messages.append({"role": "user", "content": q})
                st.experimental_rerun()
            else:
                st.warning("ë¨¼ì € ì±—ë´‡ì„ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.")

# ë©”ì¸ ì˜ì—­ êµ¬ì„±
# ì œëª© ë° ì†Œê°œ
st.title("ğŸš— í˜„ëŒ€ìë™ì°¨ ì„¤ëª…ì„œ ì±—ë´‡")
st.markdown("""
ì´ ì±—ë´‡ì€ í˜„ëŒ€ìë™ì°¨ ì•„ë°˜ë–¼ 2025 ëª¨ë¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
RAG(Retrieval-Augmented Generation) ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ PDF í˜•ì‹ì˜ ì„¤ëª…ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ ,
ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

**ì‚¬ìš© ë°©ë²•:**
1. ì‚¬ì´ë“œë°”ì—ì„œ PDF í˜•ì‹ì˜ ì„¤ëª…ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.
2. íŒŒì¼ ì—…ë¡œë“œ í›„ ìë™ìœ¼ë¡œ ë²¡í„° ì €ì¥ì†Œê°€ ìƒì„±ë˜ê³  ì±—ë´‡ì´ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.
3. ì•„ë˜ ì…ë ¥ì°½ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")

# ì±—ë´‡ ìƒì„±
if 'chatbot' not in st.session_state:
    chatbot = create_chatbot()
    if chatbot:
        st.session_state.chatbot = chatbot
        st.session_state.ready = True
else:
    chatbot = st.session_state.chatbot

# êµ¬ë¶„ì„  ì¶”ê°€
st.markdown("---")

# ì±„íŒ… ì˜ì—­
if not st.session_state.ready:
    st.info("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ì±—ë´‡ì´ ì´ˆê¸°í™”ë©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    # í™”ì‚´í‘œë¡œ ì‚¬ì´ë“œë°” ë°©í–¥ í‘œì‹œ
    st.markdown("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

# ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.container():
        st.markdown(f"""
        <div class="chat-message {'bot' if message['role'] == 'assistant' else 'user'}">
            <div class="avatar">
                {'ğŸ¤–' if message['role'] == 'assistant' else 'ğŸ‘¤'}
            </div>
            <div class="message">
                {message['content']}
            </div>
        </div>
        """, unsafe_allow_html=True)

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.container():
        st.markdown(f"""
        <div class="chat-message user">
            <div class="avatar">ğŸ‘¤</div>
            <div class="message">{prompt}</div>
        </div>
        """, unsafe_allow_html=True)
    
    if st.session_state.ready:
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            # ì±—ë´‡ì— ì§ˆë¬¸í•˜ê³  ì‘ë‹µ ë°›ê¸°
            response = st.session_state.chatbot({"question": prompt})
            answer = response["answer"]
            
            # ì°¸ê³  í˜ì´ì§€ ì¶”ì¶œ
            if "source_documents" in response:
                pages = [doc.metadata.get('page', 'N/A') for doc in response["source_documents"]]
                answer += f"\n\n**ì°¸ê³  í˜ì´ì§€**: {', '.join(map(str, pages))}"
            
            # ì±—ë´‡ ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "assistant", "content": answer})
            
            # ì±—ë´‡ ë©”ì‹œì§€ í‘œì‹œ
            with st.container():
                st.markdown(f"""
                <div class="chat-message bot">
                    <div class="avatar">ğŸ¤–</div>
                    <div class="message">{answer}</div>
                </div>
                """, unsafe_allow_html=True)
    else:
        st.error("ì±—ë´‡ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ì±—ë´‡ ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”.")

# í‘¸í„°
st.markdown("---")
st.markdown("Â© í˜„ëŒ€ìë™ì°¨ ì•„ë°˜ë–¼ 2025 ì„¤ëª…ì„œ ì±—ë´‡ | ê°œë°œ: Daniel8824") 